{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import config\n",
    "import logging\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "\n",
    "from kalm import *\n",
    "from data_utils import *\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Data path\n",
    "DATA_PATH = \"./CONLL2003/\"\n",
    "\n",
    "# Standard parameters\n",
    "TRAIN_DP = 16\n",
    "TEST_DP = 2\n",
    "BATCH_SIZE = 16\n",
    "embedding_dim = 400\n",
    "dec_units = 1150\n",
    "WH_UNITS = WE_UNITS = 100\n",
    "VOCAB_SIZE = 5000\n",
    "NB_ENTITIES = 4\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import config\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dense,Flatten,Dropout,RepeatVector,Embedding,Input,LSTM\n",
    "\n",
    "\n",
    "\n",
    "# TypeEmbedding layer\n",
    "\n",
    "class TypeEmbedding(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self,nb_entities,wh_units,we_units):\n",
    "        \n",
    "        super(TypeEmbedding,self).__init__()\n",
    "        \n",
    "        assert type(nb_entities) == int , \"Please provide integer number to number of entities\"\n",
    "        \n",
    "        self.Wh = Dense(wh_units)\n",
    "        self.We = [Dense(we_units) for _ in range(nb_entities)]\n",
    "        \n",
    "    def call(self,hidden_state):\n",
    "        \n",
    "        # hidden_state == hidden_states i.e (bs,hidden_size)\n",
    "        # Wh is used for dimentionality reduction as mentioned in paper and is shared.\n",
    "        \n",
    "        reduced_dimentionality = self.Wh(hidden_state)    # (bs,wh_units) i.e. (bs,400)\n",
    "        \n",
    "        outputs = []\n",
    "        \n",
    "        for we in self.We:\n",
    "            logits = we(reduced_dimentionality)\n",
    "            logits = tf.expand_dims(logits,axis = 0)            # (1,bs,we_units)\n",
    "            outputs.append(logits)\n",
    "            \n",
    "        outputs = tf.concat(outputs,axis=0)  # (nb_entities,bs,we_units)\n",
    "        \n",
    "        outputs = tf.transpose(outputs,perm = [1,0,2])  # (bs,nb_entities,we_units)\n",
    "        outputs = tf.nn.softmax(outputs,axis= -1)      # (bs,nb_entities,we_units)\n",
    "        \n",
    "        # code for vt\n",
    "        vt = []\n",
    "        \n",
    "        for i in range(len(self.We)):\n",
    "            logits = self.We[i](outputs[:,i,:])\n",
    "            logits = tf.expand_dims(logits,axis = 0) # (1,bs,we_units)\n",
    "            vt.append(logits)\n",
    "            \n",
    "        result = tf.concat(vt,axis=0)                   # (nb_entities,bs,we_units)\n",
    "        result = tf.transpose(result,perm= [1,2,0] )  # (bs,we_uninb_entities)\n",
    "        result = tf.reduce_sum(result,axis = -1)        # (bs,we_units)\n",
    "            \n",
    "        return outputs,result                 # (bs,nb_entities,units)  (bs,we_units)\n",
    "\n",
    "\n",
    "# Projection layer W(p,j) for j = 1,2,...K\n",
    "\n",
    "class ProjectionLayer(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self,nb_entities,wp_units):\n",
    "        \n",
    "        super(ProjectionLayer,self).__init__()\n",
    "        \n",
    "        assert type(nb_entities) == int , \"Please provide integer number to number of entities\"\n",
    "        self.Wp = [Dense(wp_units) for _ in range(nb_entities)]\n",
    "        \n",
    "    def call(self,inputs,type_prob):\n",
    "        \n",
    "        # expected inputs are hidden states of lstm. i.e (batch_size,hidden_units)\n",
    "        # type_prob - (bs,nb_entites,we_units)\n",
    "        \n",
    "        outputs = []\n",
    "        for wp in self.Wp:\n",
    "            logits = wp(inputs)\n",
    "            logits = tf.nn.softmax(logits,axis = -1)   # (bs,units)\n",
    "            logits = tf.expand_dims(logits,axis = 0)            # (1,bs,units)\n",
    "            outputs.append(logits)\n",
    "            \n",
    "        outputs = tf.concat(outputs,axis=0)  # (nb_entities,bs,units)\n",
    "        \n",
    "        outputs = tf.transpose(outputs,perm = [1,2,0])  # (bsb,nb_entities,units)\n",
    "        \n",
    "        result = tf.matmul(outputs,type_prob)\n",
    "        result = tf.reduce_sum(result,axis=-1)    # (bs,ts,vg)\n",
    "        \n",
    "        return result\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units,nb_entities,wh_units,we_units):\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        # self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        self.lstm_1 = tf.keras.layers.LSTM(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.lstm_2 = tf.keras.layers.LSTM(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "        self.lstm_3 = tf.keras.layers.LSTM(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        \n",
    "        self.type_emb = TypeEmbedding(nb_entities,wh_units,we_units)\n",
    "        self.projection = ProjectionLayer(nb_entities,vocab_size)\n",
    "\n",
    "\n",
    "    def call(self, x, hidden_state):\n",
    "        \n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        #print(\"Embedding : \",x.shape)\n",
    "        \n",
    "        \n",
    "        # Call for TypeEmbedding Layer to get vt and type_probabilities\n",
    "        # type_prob (bs,nb_entities,we_units) and vt shape is (bs,we_units)\n",
    "        type_prob , vt = self.type_emb(hidden_state)\n",
    "\n",
    "        #print(\"After type :\",type_prob.shape,vt.shape)\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(vt, 1), x], axis=-1)\n",
    "        \n",
    "        #print(\"LSTM input = \",x.shape)\n",
    "        hidden = self.lstm_1(x)\n",
    "        hidden = self.lstm_2(hidden)\n",
    "        hidden = self.lstm_3(hidden)\n",
    "        \n",
    "        #print(\"Final op : \",hidden.shape)\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        hidden = tf.reshape(hidden, (-1, hidden.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size, vocab)\n",
    "        final_result = self.projection(hidden,type_prob)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return hidden, final_result,type_prob\n",
    "    \n",
    "    def initialize_hidden_state(self,batch=None):\n",
    "\n",
    "        assert batch is not None , \"please provide batch_size...\"\n",
    "        return tf.zeros((batch,self.dec_units))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def decontracted(phrase):\n",
    "\n",
    "    \"\"\"\n",
    "    This funtion is for preprocssing the given phrase.\n",
    "    \"\"\"\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    \n",
    "    return phrase.lower()\n",
    "\n",
    "\n",
    "def read_lines(file_path):\n",
    "\n",
    "    with open(file_path,\"r\") as f:\n",
    "        train_text = f.readlines()\n",
    "    return train_text\n",
    "\n",
    "\n",
    "\n",
    "def get_data(file_path):\n",
    "    \n",
    "    train_text = read_lines(file_path)\n",
    "    \n",
    "    train = []    \n",
    "    for sent in train_text[1:]:\n",
    "        if sent.split(\" \")[0] != \"\\n\":\n",
    "            train.append(sent.split(\" \")[0])\n",
    "        else:\n",
    "            train.append(\"</s>\")\n",
    "\n",
    "    train_sent = \" \".join(train)\n",
    "    \n",
    "    train_data = []\n",
    "    for es in train_sent.split(\"</s>\"):\n",
    "        es = es.strip()\n",
    "        if len(es) > 0:\n",
    "            es = \"<s> \" + es + \" </s>\"\n",
    "            train_data.append(es)\n",
    "    \n",
    "    return [decontracted(phrase) for phrase in train_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(filename='app.log', filemode='w',level=logging.DEBUG)\n",
    "\n",
    "logging.info(\"Data preprocessed...\")\n",
    "\n",
    "#get the CONLL2003 dataset\n",
    "x_train = get_data(DATA_PATH + \"train.txt\")\n",
    "x_test = get_data(DATA_PATH + \"test.txt\")\n",
    "x_valid = get_data(DATA_PATH + \"valid.txt\")\n",
    "\n",
    "\n",
    "general_vocab = dict()\n",
    "general_vocab[\"_\"] = 0\n",
    "general_vocab[\"<s>\"] = 1\n",
    "general_vocab[\"</s>\"] = 2\n",
    "\n",
    "count = 2\n",
    "for es in x_train:\n",
    "    for ew in es.split(\" \"):\n",
    "        if ew in general_vocab:\n",
    "            pass\n",
    "        else:\n",
    "            count  += 1\n",
    "            general_vocab[ew] = count\n",
    "\n",
    "word_ix = general_vocab\n",
    "ix_word = dict()\n",
    "\n",
    "for k,v in general_vocab.items():\n",
    "    ix_word[v] = k\n",
    "\n",
    "logging.info(\"wordix and ixword dictionary created...\")\n",
    "\n",
    "train_x = [[word_ix[w] if w in word_ix else 0 for w in sent.split()] for sent in x_train]\n",
    "test_x = [[word_ix[w] if w in word_ix else 0 for w in sent.split()] for sent in x_test]\n",
    "val_x = [[word_ix[w] if w in word_ix else 0 for w in sent.split()] for sent in x_valid]\n",
    "\n",
    "max_sequence_length = 0\n",
    "\n",
    "for es in train_x:\n",
    "    if len(es) >= max_sequence_length:\n",
    "        max_sequence_length = len(es)\n",
    "\n",
    "logging.info(\"Maximum sequence length found - {}\".format(max_sequence_length))\n",
    "\n",
    "\n",
    "####################pad sequences######################\n",
    "\n",
    "train_x_padded = pad_sequences(train_x,padding=\"post\")\n",
    "test_x_padded = pad_sequences(test_x,maxlen=train_x_padded.shape[1],padding=\"post\")\n",
    "val_x_padded = pad_sequences(val_x,maxlen=train_x_padded.shape[1],padding=\"post\")\n",
    "\n",
    "train_y = train_x_padded\n",
    "test_y = test_x_padded\n",
    "val_y = val_x_padded\n",
    "\n",
    "logging.info(\"Sequence padded...\")\n",
    "\n",
    "# train data\n",
    "ds = tf.data.Dataset.from_tensor_slices((train_x_padded, train_x_padded))\n",
    "ds = ds.take(TRAIN_DP).shuffle(TRAIN_DP).batch(BATCH_SIZE)\n",
    "\n",
    "# test data\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((test_x_padded, test_x_padded))\n",
    "ds_test = ds_test.take(TEST_DP).shuffle(TEST_DP).batch(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "epoch :  0  started\n",
      "Epoch 1 Loss 0.8443\n",
      "Time taken for 1 epoch 36.05719327926636 sec\n",
      "epoch :  0  ended\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(5000,embedding_dim,dec_units,\n",
    "                        NB_ENTITIES,WH_UNITS,WE_UNITS)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 decoder=decoder)\n",
    "\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "        \n",
    "    loss_ = tf.keras.losses.sparse_categorical_crossentropy(real,pred)\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "\n",
    "def train_step(inp, targ, dec_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "\n",
    "    dec_input = tf.expand_dims([word_ix['<s>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "\n",
    "      dec_hidden,predictions,_ = decoder(dec_input,dec_hidden)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "    \n",
    "  \n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "    \n",
    "\n",
    "  grads = tape.gradient(loss, decoder.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(grads, decoder.trainable_variables))\n",
    "    \n",
    "  \n",
    "  return batch_loss\n",
    "\n",
    "\n",
    "\n",
    "######################training process###################\n",
    "\n",
    "steps_per_epoch = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  dec_hidden = decoder.initialize_hidden_state(BATCH_SIZE)\n",
    "  total_loss = 0\n",
    "\n",
    "  print(\"*\"*60)\n",
    "  print(\"epoch : \",epoch, \" started\")\n",
    "  for (batch, (inp, targ)) in enumerate(ds):\n",
    "    \n",
    "    batch_loss = train_step(inp, targ, dec_hidden)\n",
    "    total_loss += batch_loss\n",
    "    \n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec'.format(time.time() - start))\n",
    "\n",
    "  print(\"epoch : \",epoch, \" ended\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    \n",
    "    dec_hidden = decoder.initialize_hidden_state(1)\n",
    "    print(sentence.numpy())\n",
    "    dec_input = tf.expand_dims([sentence[0][1]],0)\n",
    "\n",
    "    result = \"\"\n",
    "    predict = []\n",
    "\n",
    "    logging.info(\"Evaluation\")\n",
    "    \n",
    "    for t in range(max_sequence_length):\n",
    "        \n",
    "        dec_hidden,predictions,type_prob = decoder(dec_input,dec_hidden)\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        predict.append(predicted_id)\n",
    "        print(predictions.shape)\n",
    "        result += ix_word[predicted_id] + ' '\n",
    "\n",
    "        if ix_word[predicted_id] == '</s>':\n",
    "            return result, sentence\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    logging.debug(\"result - {}\".format(result))\n",
    "\n",
    "    return result, sentence,predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(135, shape=(), dtype=int32)\n",
      "[[    1   135   344  4532   198  3813  4787  1086   231    16   500  1770\n",
      "    162    16   390    72  7704     7    80  3803  2325  3776     7 17342\n",
      "      0    11     2     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]]\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "tf.Tensor(16, shape=(), dtype=int32)\n",
      "[[   1   16  313 5953 1124   58 3815  231  158 5610 1768 3121 2485   71\n",
      "    16  651  370   11    2    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0]]\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "tf.Tensor(1757, shape=(), dtype=int32)\n",
      "[[   1 1757  639 1675 1995 6418 2303   72  344  231 3803 3776   11    2\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0]]\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "tf.Tensor(344, shape=(), dtype=int32)\n",
      "[[    1   344  1112   937   162    16  1770    87  4532  3690  3914  6345\n",
      "     28    16  2400  2299  1106     0  2162     0     0   767  6481   162\n",
      "     80     0   753  9472     7 11478    16  6362   778    16  3886   367\n",
      "  11446    87   300   158  7662  1371    11     2     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0]]\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "tf.Tensor(1675, shape=(), dtype=int32)\n",
      "[[   1 1675 1313   16 3102  162  198 5610 1768 1973   24   80 6418 1761\n",
      "  2303  745  666  231   80  390 2101 2005 1770   20 1096   11    2    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0]]\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "[[   1    0    0 3392 4644  162   16 2303  231 3839  370   72 6361  158\n",
      "     0 1154 6318 2938   52 1874  921   16 3739   11    2    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0]]\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "[[   1    0   72  818 1075 1076    0    2    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0]]\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "[[1 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0]]\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n",
      "(1, 5000)\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-8b495289d3e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-f24d9f39c0ef>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_sequence_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mdec_hidden\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtype_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdec_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mpredicted_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\kalm_model\\kalm.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, x, hidden_state)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;31m# output shape == (batch_size, vocab)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[0mfinal_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprojection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtype_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\kalm_model\\kalm.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, type_prob)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mwp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m             \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# (bs,units)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m            \u001b[1;31m# (1,bs,units)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    890\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1054\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   6109\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6110\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_post_execution_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_a\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6111\u001b[1;33m         transpose_a, \"transpose_b\", transpose_b)\n\u001b[0m\u001b[0;32m   6112\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6113\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for batch,(inp, targ) in enumerate(ds_test):\n",
    "\n",
    "    print(inp[0][1])\n",
    "    _,_,pred = evaluate(inp)\n",
    "\n",
    "    predictions.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_hidden = decoder.initialize_hidden_state(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
